{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import py4dgeo\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os, sys\n",
    "sys.path.append('../src')\n",
    "import helper, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _cloudcompare_param_mapping = {\n",
    "#     \"normalscale\": \"normal_radii\",\n",
    "#     \"registrationerror\": \"reg_error\",\n",
    "#     \"searchdepth\": \"max_distance\",\n",
    "#     \"searchscale\": \"cyl_radii\",\n",
    "#     \"usemedian\": \"robust_aggr\",\n",
    "# }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create class wise point clouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laspy_to_np_array(laspy_points):\n",
    "    x = laspy_points['x']\n",
    "    y = laspy_points['y']\n",
    "    z = laspy_points['z']\n",
    "    return np.column_stack((x, y, z))\n",
    "\n",
    "def class_split_pc(points_all_classes, type=None):\n",
    "    if type == 'real':\n",
    "        labels = points_all_classes['classification']\n",
    "        ordered_classes_dict = classes.CLASSES_FOR_M3C2_REAL\n",
    "    elif type == 'synth':\n",
    "        labels = points_all_classes.semantic_tags\n",
    "        ordered_classes_dict = classes.CLASSES_FOR_M3C2_SYNTH\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    class_wise_points = []\n",
    "    for class_number in ordered_classes_dict:\n",
    "        class_indices = np.isin(labels, class_number)\n",
    "        class_points = points_all_classes[class_indices]\n",
    "        class_points_np = laspy_to_np_array(class_points)\n",
    "        class_wise_points.append(class_points_np)\n",
    "    \n",
    "    return class_wise_points\n",
    "\n",
    "EVERY_NTH = 100\n",
    "\n",
    "def m3c2_class_wise(real_pc_path, synth_pc_path):\n",
    "    print('Reading & preparing data')\n",
    "    real_points_all_classes, synth_points_all_classes = helper.import_and_prepare_point_clouds(real_pc_path, synth_pc_path, shift_real=True, flip_synth=True, crop=True)\n",
    "    print('Splitting data')\n",
    "    real_points_class_wise = class_split_pc(real_points_all_classes, type='real')\n",
    "    synth_points_class_wise = class_split_pc(synth_points_all_classes, type='synth')\n",
    "\n",
    "    # ensure number of point clouds/classes is the same for real and synth\n",
    "    assert(len(real_points_class_wise) == len(synth_points_class_wise))\n",
    "    \n",
    "    class_wise_distances_all = []\n",
    "    class_wise_distances_medians = []\n",
    "    class_wise_uncertainties_all = []\n",
    "    class_wise_uncertainties_mean = []\n",
    "\n",
    "    print('Calculating distances...')\n",
    "    for class_number in tqdm(range(len(real_points_class_wise))):\n",
    "\n",
    "        # m3c2 needs special epoch data type, timestamp is optional \n",
    "        epoch1 = py4dgeo.Epoch(real_points_class_wise[class_number])\n",
    "        epoch2 = py4dgeo.Epoch(synth_points_class_wise[class_number])\n",
    "        \n",
    "        corepoints = epoch1.cloud[::EVERY_NTH]\n",
    "\n",
    "        #TODO adjust params\n",
    "        m3c2 = py4dgeo.M3C2(epochs=(epoch1, epoch2),\n",
    "            corepoints=corepoints,\n",
    "            cyl_radii=(2.0,),\n",
    "            normal_radii=(0.5, 1.0, 2.0)\n",
    "            )\n",
    "        distances, uncertainties = m3c2.run()\n",
    "\n",
    "        distances = np.array(distances)\n",
    "        uncertainties = np.array(uncertainties)\n",
    "\n",
    "        median_distance = np.median(distances)\n",
    "        median_uncertainty = np.median(uncertainties)\n",
    "\n",
    "        class_wise_distances_all.append(distances)\n",
    "        class_wise_distances_medians.append(median_distance)\n",
    "        class_wise_uncertainties_all.append(uncertainties)\n",
    "        class_wise_uncertainties_mean.append(median_uncertainty)\n",
    "\n",
    "    return class_wise_distances_medians, class_wise_uncertainties_mean, class_wise_uncertainties_all, class_wise_uncertainties_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_pc_path = '/home/Meins/Uni/TUM/SS23/Data Lab/Data Sets/Synthetic/Val_1 - Cloud.las'\n",
    "real_pc_path = '/home/Meins/Uni/TUM/SS23/Data Lab/Labelling/Label-Datasets/train/Train1 - labelled.las'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_points_all_classes, synth_points_all_classes = helper.import_and_prepare_point_clouds(real_pc_path, synth_pc_path, shift_real=True, flip_synth=True, crop=True)\n",
    "#real_points_class_wise = class_split_pc(real_points_all_classes, type='real')\n",
    "#synth_points_class_wise = class_split_pc(synth_points_all_classes, type='synth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading & preparing data\n",
      "Splitting data\n",
      "Calculating distances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[2023-07-11 08:09:19][INFO] Building KDTree structure with leaf parameter 10\n",
      "[2023-07-11 08:09:22][INFO] Building KDTree structure with leaf parameter 10\n"
     ]
    }
   ],
   "source": [
    "distances_medians, uncertainties_mean, uncertainties_all, uncertainties_all = m3c2_class_wise(real_pc_path, synth_pc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
